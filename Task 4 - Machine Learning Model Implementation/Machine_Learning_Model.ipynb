{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5dab5a7-421f-4269-8f97-fa93dec403c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully. First 5 rows:\n",
      "     v1                                                 v2 Unnamed: 2  \\\n",
      "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
      "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
      "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n",
      "2        NaN        NaN  \n",
      "3        NaN        NaN  \n",
      "4        NaN        NaN  \n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n",
      "\n",
      "Missing values per column:\n",
      "v1               0\n",
      "v2               0\n",
      "Unnamed: 2    5522\n",
      "Unnamed: 3    5560\n",
      "Unnamed: 4    5566\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "# Make sure 'spam.csv' is in the same directory as your Jupyter Notebook\n",
    "try:\n",
    "    df = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "except UnicodeDecodeError:\n",
    "    # Some versions might need a different encoding\n",
    "    df = pd.read_csv('spam.csv', encoding='ISO-8859-1')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'spam.csv' not found. Make sure it's in the correct directory.\")\n",
    "    # If the file has a different name, update it here, e.g., 'SMSSpamCollection'\n",
    "    # df = pd.read_csv('SMSSpamCollection', sep='\\t', names=['label', 'message'])\n",
    "\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"Dataset loaded successfully. First 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display basic info about the dataset\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baf8bb0d-f777-4ed8-9679-2def034d0119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after cleaning and renaming columns:\n",
      "  label                                            message\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "\n",
      "Cleaned Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   label    5572 non-null   object\n",
      " 1   message  5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Drop the unnecessary columns\n",
    "# Assuming the extra columns are Unnamed: 2, Unnamed: 3, Unnamed: 4\n",
    "df = df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], errors='ignore')\n",
    "\n",
    "# Rename the columns for clarity\n",
    "df = df.rename(columns={'v1': 'label', 'v2': 'message'})\n",
    "\n",
    "# Display the first few rows of the cleaned dataset\n",
    "print(\"Dataset after cleaning and renaming columns:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check the new column names and info\n",
    "print(\"\\nCleaned Dataset Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd1acd6e-ebf2-4355-afff-2fc9bf885d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after encoding 'label' column:\n",
      "   label                                            message\n",
      "0      0  Go until jurong point, crazy.. Available only ...\n",
      "1      0                      Ok lar... Joking wif u oni...\n",
      "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      0  U dun say so early hor... U c already then say...\n",
      "4      0  Nah I don't think he goes to usf, he lives aro...\n",
      "\n",
      "Unique encoded labels:\n",
      "[0 1]\n",
      "\n",
      "Label counts:\n",
      "label\n",
      "0    4825\n",
      "1     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'label' column\n",
    "df['label'] = encoder.fit_transform(df['label'])\n",
    "\n",
    "# Display the first few rows to see the encoded labels\n",
    "print(\"Dataset after encoding 'label' column:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display the unique encoded labels\n",
    "print(\"\\nUnique encoded labels:\")\n",
    "print(df['label'].unique())\n",
    "\n",
    "# Check the count of 'ham' (0) and 'spam' (1)\n",
    "print(\"\\nLabel counts:\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dab1e238-36d1-4b19-b86d-bcd159f24a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Vectorization and Data Splitting complete.\n",
      "Shape of X_train (training features): (4457, 5000)\n",
      "Shape of X_test (testing features): (1115, 5000)\n",
      "Shape of y_train (training labels): (4457,)\n",
      "Shape of y_test (testing labels): (1115,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "# max_features limits the number of features (words) to consider, common for text data\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the 'message' column\n",
    "# X will be the features (vectorized messages)\n",
    "X = tfidf_vectorizer.fit_transform(df['message']).toarray()\n",
    "\n",
    "# y will be the labels (encoded spam/ham)\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# test_size=0.2 means 20% of data for testing, 80% for training\n",
    "# random_state ensures reproducibility of the split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Text Vectorization and Data Splitting complete.\")\n",
    "print(f\"Shape of X_train (training features): {X_train.shape}\")\n",
    "print(f\"Shape of X_test (testing features): {X_test.shape}\")\n",
    "print(f\"Shape of y_train (training labels): {y_train.shape}\")\n",
    "print(f\"Shape of y_test (testing labels): {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb6f382-7822-417a-ae65-8aee39e3c7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes model\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Train the model using the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# --- Model Evaluation (Next Part) ---\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"\\nModel Evaluation:\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f\"Precision (Spam): {precision:.4f}\") # Precision for class 1 (spam)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f\"Recall (Spam): {recall:.4f}\") # Recall for class 1 (spam)\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1-Score (Spam): {f1:.4f}\") # F1-Score for class 1 (spam)\n",
    "\n",
    "# Generate Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Plot Confusion Matrix for better visualization\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Ham (Predicted)', 'Spam (Predicted)'],\n",
    "            yticklabels=['Ham (Actual)', 'Spam (Actual)'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e095905-e249-498f-9702-42143ad642ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
